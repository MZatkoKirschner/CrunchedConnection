{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crunched Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This tool uses flight records, archived weather forecasts, and supervised machine learning to determine likelihood of missing an upcoming flight connection. Flight data from U.S. Bureau of Transportation Statistics, weather data from National Weather Service Archives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare merged flight and weather dataset so it can be used as input in ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read merged flight+met data for ML and perform slight processing\n",
    "file2019 = '../data/processed/merged/2019_FlightMetMerged.csv'\n",
    "df2019 = pd.read_csv(file2019)\n",
    "\n",
    "file2018 = '../data/processed/merged/2018_FlightMetMerged.csv'\n",
    "df2018 = pd.read_csv(file2018)\n",
    "\n",
    "file2017 = '../data/processed/merged/2017_FlightMetMerged.csv'\n",
    "df2017 = pd.read_csv(file2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine 2017, 2018, 2019\n",
    "dftmp = [df2017,df2018,df2019]\n",
    "df = pd.concat(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where cancellations are not due to weather\n",
    "dfcc = df[ (df['CANCELLATION_CODE']!='A') & (df['CANCELLATION_CODE']!='C') & (df['CANCELLATION_CODE']!='D') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prevent exclusion of cancelled flights due to weather\n",
    "dfcc.loc[(dfcc['CANCELLATION_CODE']=='B'),'ARR_DELAY_GROUP'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where there is a delay that isn't at least partially due to severe weather\n",
    "dfccOnlyWxDelay = dfcc[~(dfcc['WEATHER_DELAY']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure flights cancelled from weather are still in dataset\n",
    "dfccOnlyWxDelay.loc[(dfccOnlyWxDelay['CANCELLATION_CODE']=='B'),'ARR_DELAY_GROUP'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop cancellation, diversion, and delay information columns from dataset\n",
    "dfccOnlyWxDelay.drop(columns=['CANCELLED','DIVERTED','WEATHER_DELAY','NAS_DELAY','LATE_AIRCRAFT_DELAY','CANCELLATION_CODE'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any rows with missing values\n",
    "dfML = dfccOnlyWxDelay.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge arrival bins for binary classification\n",
    "\n",
    "#Less than 15 minutes late (which is considered on-time)\n",
    "dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']<=0)] = 0\n",
    "\n",
    "#More than 15 minutes late\n",
    "dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']>0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe name change \n",
    "dfMLmerged = dfML.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode categorical variable\n",
    "dfMLmerged['OP_UNIQUE_CARRIER'].replace({'MQ':1,'AA':2,'B6':3,'OO':4,'OH':5,'UA':6,'AS':7,'NK':8,\n",
    "                                 'YX':9,'YV':10,'WN':11,'DL':12,'EV':13,'9E':14,'F9':15,'HA':16,'G4':17,'VX':18},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment with features based on time of flight\n",
    "dfMLmerged['DEP_TIME'] = pd.to_datetime(dfMLmerged['DEP_TIME'])\n",
    "dfMLmerged['ARR_TIME'] = pd.to_datetime(dfMLmerged['ARR_TIME'])\n",
    "\n",
    "#Convert date infomation to feature info\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.month==12) | (dfMLmerged['DEP_TIME'].dt.month==1) | (dfMLmerged['DEP_TIME'].dt.month==2),'SEASON'] = 1\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.month==3) | (dfMLmerged['DEP_TIME'].dt.month==4) | (dfMLmerged['DEP_TIME'].dt.month==5),'SEASON'] = 2\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.month==6) | (dfMLmerged['DEP_TIME'].dt.month==7) | (dfMLmerged['DEP_TIME'].dt.month==8),'SEASON'] = 3\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.month==9) | (dfMLmerged['DEP_TIME'].dt.month==10) | (dfMLmerged['DEP_TIME'].dt.month==11),'SEASON'] = 4\n",
    "\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.hour>=1) | (dfMLmerged['DEP_TIME'].dt.hour<=8),'TOD'] = 1\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.hour>=9) | (dfMLmerged['DEP_TIME'].dt.hour<=14),'TOD'] = 2\n",
    "dfMLmerged.loc[(dfMLmerged['DEP_TIME'].dt.hour>=15) | (dfMLmerged['DEP_TIME'].dt.hour<=23),'TOD'] = 3\n",
    "\n",
    "dfMLmerged['month'] = dfMLmerged['DEP_TIME'].dt.month\n",
    "dfMLmerged['hour'] = dfMLmerged['DEP_TIME'].dt.hour\n",
    "dfMLmerged['DOW'] = dfMLmerged['DEP_TIME'].dt.dayofweek\n",
    "dfMLmerged['DOY'] = dfMLmerged['DEP_TIME'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify which features to include in ML model\n",
    "X = dfMLmerged[['spd_D', 'fzRnPrb_D', 'snowPrb_D', '6hrTsPrb_15mi_D',\n",
    "       '6hrSvrTsPrb_25mi_D', 'fzRnPrb_A', 'snowPrb_A', '6hrTsPrb_15mi_A',\n",
    "       '6hrSvrTsPrb_25mi_A', '6hPrecPrb_D', '6hPrecPrb_A', '12hPrecPrb_D',\n",
    "       '12hPrecPrb_A', 'snow_D', 'snow_A', 'spd_A', 'tmpF_D', 'dptF_D',\n",
    "       'tmpF_A', 'dptF_A', 'ceil_D', 'ceil_A', 'visib_D', 'visib_A',\n",
    "       '6hQntPrec_D', '6hQntPrec_A', '12hQntPrec_A', '12hQntPrec_D',\n",
    "       'OP_UNIQUE_CARRIER', 'DISTANCE_GROUP', 'month', 'hour', 'DOY']]\n",
    "\n",
    "y = dfMLmerged['ARR_DELAY_GROUP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and test set, then balance the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split conversion dataset into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy='minority',random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_over, y_train_over = over.fit_resample(X_train, y_train)\n",
    "\n",
    "# define understampling strategt\n",
    "under = RandomUnderSampler(sampling_strategy='majority',random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_under, y_train_under = under.fit_resample(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train random forest model\n",
    "#clf = RandomForestClassifier(n_estimators=20,n_jobs=5,class_weight='balanced',random_state=42,max_features=10).fit(X_train_under, y_train_under)\n",
    "clf = RandomForestClassifier(n_estimators=10,n_jobs=5,class_weight='balanced',random_state=42,max_features=10).fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained model to a pickle file\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try out XGBoost and sklearn gradient boosting ML models\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "#model_xgb = XGBClassifier(random_state=42,n_estimators=10).fit(X_train_under, y_train_under)\n",
    "\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#gb_clf = GradientBoostingClassifier(n_estimators=20,random_state=42).fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run trained model on test set\n",
    "\n",
    "forest_predicted = clf.predict(X_test)\n",
    "#forest_predicted = gb_clf.predict(X_test)\n",
    "#forest_predicted = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, forest_predicted,target_names=['0', '1']))\n",
    "\n",
    "print (' ')\n",
    "\n",
    "print('Micro-averaged precision = {:.2f} (treat instances equally)'\n",
    "       .format(precision_score(y_test, forest_predicted, average = 'micro')))\n",
    "print('Macro-averaged precision = {:.2f} (treat classes equally)'\n",
    "      .format(precision_score(y_test, forest_predicted, average = 'macro')))\n",
    "print('Micro-averaged f1 = {:.2f} (treat instances equally)'\n",
    "      .format(f1_score(y_test, forest_predicted, average = 'micro')))\n",
    "print('Macro-averaged f1 = {:.2f} (treat classes equally)'\n",
    "      .format(f1_score(y_test, forest_predicted, average = 'macro')))\n",
    "\n",
    "print (' ')\n",
    "\n",
    "print('Matthews correlation coefficient = {:.2f}'\n",
    "      .format(matthews_corrcoef(y_test, forest_predicted)))\n",
    "\n",
    "print('Cohen kappa score = {:.2f}'\n",
    "      .format(cohen_kappa_score(y_test, forest_predicted)))\n",
    "\n",
    "print (' ')\n",
    "print ('Confusion Matrix')\n",
    "confusion_matrix(y_test, forest_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine feature importance\n",
    "features = X\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "#importances = list(model_xgb.feature_importances_)\n",
    "#importances = list(gb_clf.feature_importances_)\n",
    "importances = list(clf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:12} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict probabilities associated with test set\n",
    "#predictions = clf.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
