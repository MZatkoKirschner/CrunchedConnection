{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this tool 2-3 days before your flight to determine if it is likely that your flight connection will be missed due to weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Connection tool uses historical flight data, archived weather forecast data, and a machine learning algorithm to estimate if you are likely to miss your connection due to extreme weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input: Specify origin, connection, and final airports (4 letter code), along with scheduled deparature and arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserOrigin = 'KBOI'\n",
    "UserDepartureYear = 2019\n",
    "UserDepartureMonth = 10\n",
    "UserDepartureDay = 6\n",
    "UserScheduledDepartureTime = '11:00' #local time\n",
    "\n",
    "UserConnectingAirport = 'KBOS'\n",
    "UserArrivalYear = 2019\n",
    "UserArrivalMonth = 10\n",
    "UserArrivalDay = 6\n",
    "UserScheduledArrivalTime = '20:00' #local time\n",
    "\n",
    "UserDestinationAirport = 'KDCA'\n",
    "UserFinalYear = 2019\n",
    "UserFinalMonth = 10\n",
    "UserFinalDay = 6\n",
    "UserScheduledFinalTime = '22:00' #local time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ------- Behind the scenes --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in met data so we can pair user-specified flight info with it, read in merged flight+met data for ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read met data\n",
    "metfile = '../data/processed/met/2019_ProcessedMet.csv'\n",
    "dfMet = pd.read_csv(metfile)\n",
    "\n",
    "#Formatting to help with merge\n",
    "dfMet['timeLocal'] = pd.to_datetime(dfMet['timeLocal'])\n",
    "dfMet['ORIGIN'] = dfMet['airport']\n",
    "dfMet['DEST'] = dfMet['airport']\n",
    "dfMet.sort_values(by=['timeLocal'],inplace=True)\n",
    "\n",
    "#Forward-fill met data for now (note this is not the final place for this)\n",
    "dfMet.fillna(method='ffill',inplace=True)\n",
    "\n",
    "#Read merged flight+met data for ML and perform slight processing\n",
    "file = '../data/processed/merged/2019_FlightMetMerged.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#For now remove flights where arrival time before departure time\n",
    "df['ARR_TIME'] = pd.to_datetime(df['ARR_TIME'])\n",
    "df['DEP_TIME'] = pd.to_datetime(df['DEP_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert user-input into df-compatible format\n",
    "depTime = str(UserDepartureYear)+'-'+str(UserDepartureMonth)+'-'+str(UserDepartureDay)+' '+UserScheduledDepartureTime\n",
    "depTime = pd.to_datetime(depTime)\n",
    "\n",
    "arrTime = str(UserArrivalYear)+'-'+str(UserArrivalMonth)+'-'+str(UserArrivalDay)+' '+UserScheduledArrivalTime\n",
    "arrTime = pd.to_datetime(arrTime)\n",
    "\n",
    "orgCode = df[df['ORIGIN']==UserOrigin]['ORIGIN_AIRPORT_ID'].iloc[0]\n",
    "depCode = df[df['DEST']==UserConnectingAirport]['DEST_AIRPORT_ID'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a row of 'X' (called_dfUser) based upon given flight data, pair with appropriate meteorology\n",
    "dftmp = df[['ORIGIN_AIRPORT_ID','DEST_AIRPORT_ID','DEP_TIME','ARR_TIME']].iloc[0]\n",
    "dfUser1 = pd.DataFrame(data=dftmp).transpose()\n",
    "dfUser1['ORIGIN'] = UserOrigin\n",
    "dfUser1['DEST'] = UserConnectingAirport\n",
    "dfUser1['ORIGIN_AIRPORT_ID'] = orgCode\n",
    "dfUser1['DEST_AIRPORT_ID'] = depCode\n",
    "dfUser1['DEP_TIME'] = depTime\n",
    "dfUser1['ARR_TIME'] = arrTime\n",
    "\n",
    "#Link in meteorology at the departure airport\n",
    "dfUser2 = pd.merge_asof(left=dfUser1,right=dfMet,left_on=['DEP_TIME'],right_on=['timeLocal'],by=['ORIGIN'])\n",
    "\n",
    "#Drop columns no longer needed and rename met columns so we know those are tied to departure\n",
    "dfUser2.drop(['timeLocal','airport','DEST_y'],axis=1,inplace=True)\n",
    "dfUser2.rename(columns={'DEST_x':'DEST','tmpF':'tmpF_D','dptF':'dptF_D','CC':'CC_D','dir':'dir_D',\n",
    "        'spd':'spd_D','6hPrecPrb':'6hPrecPrb_D','12hPrecPrb':'12hPrecPrb_D',\n",
    "        '6hQntPrec':'6hQntPrec_D','12hQntPrec':'12hQntPrec_D','snow':'snow_D',\n",
    "        'ceil':'ceil_D','visib':'visib_D','obstruc':'obstruc_D','fzRnPrb':'fzRnPrb_D',\n",
    "        'snowPrb':'snowPrb_D','6hrTsPrb_15mi':'6hrTsPrb_15mi_D',\n",
    "        '6hrSvrTsPrb_25mi':'6hrSvrTsPrb_25mi_D'},inplace=True)\n",
    "\n",
    "#Link in meteorology at the arrival airport\n",
    "dfUser2.sort_values(by=['ARR_TIME'],inplace=True)\n",
    "dfUser = pd.merge_asof(left=dfUser2,right=dfMet,left_on=['ARR_TIME'],right_on=['timeLocal'],\n",
    "            by=['DEST'])\n",
    "\n",
    "dfUser.drop(['timeLocal','airport','ORIGIN_y'],axis=1,inplace=True)\n",
    "dfUser.rename(columns={'ORIGIN_x':'ORIGIN','tmpF':'tmpF_A','dptF':'dptF_A','CC':'CC_A','dir':'dir_A',\n",
    "            'spd':'spd_A','6hPrecPrb':'6hPrecPrb_A','12hPrecPrb':'12hPrecPrb_A',\n",
    "            '6hQntPrec':'6hQntPrec_A','12hQntPrec':'12hQntPrec_A','snow':'snow_A',\n",
    "            'ceil':'ceil_A','visib':'visib_A','obstruc':'obstruc_A','fzRnPrb':'fzRnPrb_A',\n",
    "            'snowPrb':'snowPrb_A','6hrTsPrb_15mi':'6hrTsPrb_15mi_A',\n",
    "            '6hrSvrTsPrb_25mi':'6hrSvrTsPrb_25mi_A'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/insight/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-8-74eb020b933a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']<=0)] = 0\n",
      "<ipython-input-8-74eb020b933a>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']>0)] = 1\n"
     ]
    }
   ],
   "source": [
    "#For df used for ML modeling \n",
    "\n",
    "#Drop any row from df with nans for ML model, drop columns columns that are not needed\n",
    "dfML = df.dropna() \n",
    "\n",
    "#Merged arrival bins for simplicity for now\n",
    "dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']<=0)] = 0\n",
    "dfML['ARR_DELAY_GROUP'].loc[(dfML['ARR_DELAY_GROUP']>0)] = 1\n",
    "\n",
    "#Use subset of dfML for ML modeling\n",
    "X = dfML[['tmpF_D', 'dptF_D','dir_D', 'spd_D', '6hPrecPrb_D', \n",
    "          '6hQntPrec_D', 'ceil_D', 'visib_D','fzRnPrb_D', 'snowPrb_D', '6hrTsPrb_15mi_D',\n",
    "          '6hrSvrTsPrb_25mi_D', 'tmpF_A', 'dptF_A', 'dir_A', 'spd_A','6hPrecPrb_A', '6hQntPrec_A', 'ceil_A', \n",
    "          'visib_A','fzRnPrb_A', 'snowPrb_A', '6hrTsPrb_15mi_A','6hrSvrTsPrb_25mi_A','snow_D','snow_A',\n",
    "          '12hPrecPrb_D','12hQntPrec_D','12hPrecPrb_A','12hQntPrec_A']]\n",
    "\n",
    "y = dfML['ARR_DELAY_GROUP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Normalize dataset, make sure to include the user data row is in here so it gets scaled\n",
    "dfUser = dfUser[['tmpF_D', 'dptF_D', 'dir_D', 'spd_D', '6hPrecPrb_D', '6hQntPrec_D','ceil_D', 'visib_D', \n",
    "                 'fzRnPrb_D', 'snowPrb_D', '6hrTsPrb_15mi_D','6hrSvrTsPrb_25mi_D', 'tmpF_A', 'dptF_A', \n",
    "                 'dir_A', 'spd_A','6hPrecPrb_A', '6hQntPrec_A', 'ceil_A', 'visib_A', 'fzRnPrb_A','snowPrb_A', \n",
    "                 '6hrTsPrb_15mi_A', '6hrSvrTsPrb_25mi_A', 'snow_D','snow_A', '12hPrecPrb_D', '12hQntPrec_D', \n",
    "                 '12hPrecPrb_A','12hQntPrec_A']]\n",
    "\n",
    "#Make a dataframe with X plus user data\n",
    "XwithUsertmp = [X,dfUser]\n",
    "XwithUser = pd.concat(XwithUsertmp)\n",
    "\n",
    "#Perform scaling\n",
    "sc = MinMaxScaler()\n",
    "data = sc.fit_transform(XwithUser)\n",
    "\n",
    "#Separate X from user data\n",
    "Xdata = data[:-1,:]\n",
    "\n",
    "XUser = data[-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split conversion dataset into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train random forest model\n",
    "clf = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest user-provided data into trained ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run random forest model using user-provided data\n",
    "XUserT = XUser.reshape(1, -1)\n",
    "forest_predicted = clf.predict(XUserT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- end behind the scenes ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Information for Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to make your connection!\n"
     ]
    }
   ],
   "source": [
    "if (forest_predicted==0):\n",
    "    print (\"You are going to make your connection!\")\n",
    "else:\n",
    "    print (\"You are likely going to miss your connection!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
